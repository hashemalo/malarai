{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbOpF3SKW-Gs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#INITIALIZING VARIABLES\n",
        "\n",
        "ds, info = tfds.load('malaria', split = 'train', shuffle_files = True, with_info = True)\n",
        "\n",
        "train_ds, test_ds = tfds.load(\n",
        "  'malaria',\n",
        "  split = ['train[:70%]', 'train[70%:]'],\n",
        "  shuffle_files = True, as_supervised = True,\n",
        ")\n",
        "\n",
        "NUM_TRAIN_IMAGES = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "print(NUM_TRAIN_IMAGES)\n",
        "\n",
        "NUM_TEST_IMAGES = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "print(NUM_TEST_IMAGES)\n",
        "\n",
        "vis = tfds.visualization.show_examples(ds, info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#PROCESSING DATA\n",
        "\n",
        "\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"Image size: \", image.numpy().shape)\n",
        "    print(\"Label: \", label.numpy())\n",
        "\n",
        "#To clean the data, we will resize the images to be 200 x 200 pixels\n",
        "# and invert the labels to have 0 represent uninfected cells and 1 represent parasitized ones\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = [200, 200]\n",
        "\n",
        "def convert(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  return image, label\n",
        "\n",
        "# resizing each image to 200 x 200\n",
        "def pad(image,label):\n",
        "  image,label = convert(image, label)\n",
        "  image = tf.image.resize_with_crop_or_pad(image, 200, 200)\n",
        "  return image, label\n",
        "\n",
        "# switching the 0 and 1 around, as mentioned above\n",
        "def invert_labels(image, label):\n",
        " return image, label\n",
        "\n",
        "clean_train_ds = (\n",
        "    train_ds\n",
        "    .map(pad)\n",
        "    .map(invert_labels)\n",
        ")\n",
        "\n",
        "clean_test_ds = (\n",
        "    test_ds\n",
        "    .map(pad)\n",
        "    .map(invert_labels)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#THE CLEAN DATA\n",
        "\n",
        "#Visualizing the data\n",
        "image_batch, label_batch = next(iter(clean_train_ds.batch(BATCH_SIZE)))\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "    plt.figure(figsize = (10, 10))\n",
        "    for n in range(25):\n",
        "        ax = plt.subplot(5, 5, n+1)\n",
        "        plt.imshow(image_batch[n])\n",
        "        if label_batch[n]:\n",
        "            plt.title(\"parasitized (1) \")\n",
        "        else:\n",
        "            plt.title(\"uninfected (0) \")\n",
        "        plt.axis(\"off\")\n",
        "show_batch(image_batch.numpy(), label_batch.numpy())\n",
        "\n",
        "#Sending the data in batches to the model for training and testing\n",
        "clean_train_ds = clean_train_ds.repeat().shuffle(NUM_TRAIN_IMAGES).batch(BATCH_SIZE)\n",
        "clean_test_ds = clean_test_ds.batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#THE MODEL\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "    # CNN: this is the convolutional part of the neural network, how the computer sees the cell\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = tf.nn.relu, input_shape = (200, 200, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides = 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides = 2),\n",
        "\n",
        "    # Dense and output layers:\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(300, activation = tf.nn.relu),\n",
        "  tf.keras.layers.Dense(300, activation = tf.nn.relu),\n",
        "  tf.keras.layers.Dense(200, activation = tf.nn.relu),\n",
        "  tf.keras.layers.Dense(200, activation = tf.nn.relu),\n",
        "  tf.keras.layers.Dense(100, activation = tf.nn.relu),\n",
        "  tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)\n",
        "\n",
        "])\n",
        "\n",
        "model.summary() # this is going to print a quick little summary of our model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#COMPILING THE MODEL\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = [tf.keras.metrics.TruePositives(),\n",
        "                         tf.keras.metrics.TrueNegatives(),\n",
        "                         tf.keras.metrics.FalsePositives(),\n",
        "                         tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#TRAINING\n",
        "\n",
        "NUMBER_OF_EPOCHS = 5\n",
        "\n",
        "model.fit(clean_train_ds, epochs = NUMBER_OF_EPOCHS, steps_per_epoch = math.ceil(NUM_TRAIN_IMAGES / BATCH_SIZE))\n",
        "\n",
        "#Results from training\n",
        "print(\"\"\"Epoch 1/5\n",
        "603/603 [==============================] - 94s 99ms/step - loss: 0.4499 - true_positives: 7784.0000 - true_negatives: 7205.0000 - false_positives: 2407.0000 - false_negatives: 1900.0000\n",
        "Epoch 2/5\n",
        "603/603 [==============================] - 62s 103ms/step - loss: 0.2367 - true_positives: 9111.0000 - true_negatives: 8731.0000 - false_positives: 912.0000 - false_negatives: 542.0000\n",
        "Epoch 3/5\n",
        "603/603 [==============================] - 61s 102ms/step - loss: 0.1923 - true_positives: 9105.0000 - true_negatives: 9032.0000 - false_positives: 585.0000 - false_negatives: 574.0000\n",
        "Epoch 4/5\n",
        "603/603 [==============================] - 61s 100ms/step - loss: 0.1716 - true_positives: 9220.0000 - true_negatives: 9075.0000 - false_positives: 604.0000 - false_negatives: 397.0000\n",
        "Epoch 5/5\n",
        "603/603 [==============================] - 62s 102ms/step - loss: 0.1569 - true_positives: 9167.0000 - true_negatives: 9132.0000 - false_positives: 596.0000 - false_negatives: 401.0000\n",
        "<keras.callbacks.History at 0x7f0ac2a31050>\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#PERFORMANCE ON TEST DATA\n",
        "\n",
        "#Beginning testing\n",
        "test_loss, test_tp, test_tn, test_fp, test_fn = model.evaluate(clean_test_ds, steps = math.ceil(NUM_TEST_IMAGES/BATCH_SIZE))\n",
        "\n",
        "#Creating a confusion matrix using Seaborn\n",
        "def draw_confusion_matrix(tp, tn, fp, fn):\n",
        "  cf_matrix = np.array([[tp, fp], [fn, tn]])\n",
        "  group_names = ['True Pos','False Pos','False Neg','True Neg']\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "  labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(2,2)\n",
        "  sns.heatmap(cf_matrix, annot = labels, fmt = '', cmap = 'Blues', xticklabels = False, yticklabels = False)\n",
        "\n",
        "  draw_confusion_matrix(test_tp, test_tn, test_fp, test_fn)\n",
        "\n",
        "#Calculating Accuracy\n",
        "accuracy = (test_tp + test_tn) / (test_tp + test_tn + test_fp + test_fn)\n",
        "print(\"The accuracy of this model is %.7f, or about %d%%.\" % (accuracy, round(accuracy*100)))\n",
        ""
      ]
    }
  ]
}